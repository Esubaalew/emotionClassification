{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Import Libraries\n",
    "This section imports all the necessary libraries for data processing, text cleaning, and emotion classification."
   ],
   "id": "d3bf6078209a4a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import langdetect"
   ],
   "id": "1b6b772a4aa7d6d6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load and Preprocess Data\n",
    "This section loads the JSON file containing the chat data, extracts messages of type 'message', and creates a DataFrame."
   ],
   "id": "362546f12b96ff57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('/data/chat.json', 'r', encoding='utf-8') as file:\n",
    "    chat_data = json.load(file)\n",
    "\n",
    "messages = [msg for msg in chat_data['messages'] if msg['type'] == 'message']\n",
    "\n",
    "def extract_text(msg):\n",
    "    if 'text' in msg:\n",
    "        if isinstance(msg['text'], list):\n",
    "            return ''.join([part['text'] if isinstance(part, dict) else part for part in msg['text']])\n",
    "        return msg['text']\n",
    "    return ''\n",
    "\n",
    "texts = [extract_text(msg) for msg in messages]\n",
    "\n",
    "df = pd.DataFrame({'text': texts})\n",
    "print(f\"Total messages: {len(df)}\")\n",
    "\n",
    "df = df[df['text'].str.strip() != '']\n",
    "print(f\"After removing empty texts: {len(df)}\")"
   ],
   "id": "b99cb51e5b05daf4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Text Cleaning\n",
    "This section cleans the text by removing URLs, special characters, and numbers. It also converts the text to lowercase."
   ],
   "id": "df8420c6c632b9f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "def process_sentences(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    cleaned_sentences = []\n",
    "    for sent in sentences:\n",
    "        sent = clean_text(sent)\n",
    "        if len(sent.split()) > 3:\n",
    "            try:\n",
    "                if langdetect.detect(sent) == 'en':\n",
    "                    cleaned_sentences.append(sent)\n",
    "            except:\n",
    "                continue\n",
    "    return ' '.join(cleaned_sentences)\n",
    "\n",
    "df['text'] = df['text'].apply(process_sentences)\n",
    "print(f\"After removing non-English and short texts: {len(df)}\")\n",
    "\n",
    "df = df[df['text'].str.strip() != '']\n",
    "print(f\"After final filtering: {len(df)}\")"
   ],
   "id": "4267ba869762021a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Model and Tokenizer\n",
    "This section loads the pre-trained emotion classification model and tokenizer. It also checks if a GPU is available for faster processing."
   ],
   "id": "5ebe715a86f5939"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using device: {'GPU' if device == 0 else 'CPU'}\")\n",
    "\n",
    "emotion_classifier = pipeline(task='text-classification', model='j-hartmann/emotion-english-distilroberta-base', truncation=True, padding=True, device=device)\n",
    "tokenizer = AutoTokenizer.from_pretrained('j-hartmann/emotion-english-distilroberta-base')"
   ],
   "id": "a10ea2f7bbda7fac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Truncate Text\n",
    "This section truncates text that exceeds the model's maximum input length (512 tokens)."
   ],
   "id": "e0564ea4f241abfb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def truncate_text(text, max_length=512):\n",
    "    tokenized = tokenizer(text, truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    return tokenizer.decode(tokenized[\"input_ids\"][0], skip_special_tokens=True)\n",
    "\n",
    "df['text'] = df['text'].apply(truncate_text)"
   ],
   "id": "3c4be2f8b5055e0f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Emotion Prediction\n",
    "This section processes the text in batches and predicts emotions using the pre-trained model."
   ],
   "id": "5150a615e9929149"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict_emotions(texts, batch_size=32):\n",
    "    results = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i : i + batch_size]\n",
    "        try:\n",
    "            predictions = emotion_classifier(batch)\n",
    "            emotions = [pred['label'] for pred in predictions]\n",
    "            results.extend(emotions)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Skipping batch due to error: {e}\")\n",
    "            results.extend([\"UNKNOWN\"] * len(batch))\n",
    "    return results\n",
    "\n",
    "df['emotion'] = predict_emotions(df['text'].tolist(), batch_size=32)"
   ],
   "id": "bfebafaaa2db423"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Save Results\n",
    "This section saves the final DataFrame, including the original text and predicted emotions, to a CSV file."
   ],
   "id": "fb4244c624f69f91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.to_csv('chat_emotions.csv', index=False)\n",
    "print(\"Emotion analysis completed and saved.\")"
   ],
   "id": "bce4be46af6eceb4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
